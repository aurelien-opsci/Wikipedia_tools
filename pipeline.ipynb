{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--start START] [--end END] [--json]\n",
      "                             pages [pages ...]\n",
      "ipykernel_launcher.py: error: the following arguments are required: pages\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cytech/mon_env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# wikipedia_scoring_pipeline.py\n",
    "\"\"\"\n",
    "Pipeline pour calculer les scores Heat, Quality, ActorRisk et le score global\n",
    "à partir des scripts Jupyter existants.\n",
    "\n",
    "Hypothèses :\n",
    "- Chaque notebook a été factorisé en un module Python exposant une fonction\n",
    "  qui renvoie la métrique principale sous forme de Pandas Series ou scalaire.\n",
    "  * ano_editor   -> get_anon_edit_share(pages, start, end)\n",
    "  * edit         -> get_revert_rate(pages, start, end)\n",
    "  * pageviews    -> get_pageview_spikes(pages, start, end)\n",
    "  * protection   -> get_protection_level(pages)\n",
    "  * taille_talk  -> get_talk_activity(pages, start, end)\n",
    "  * ref          -> get_citation_gap(pages)\n",
    "  * readability  -> get_readability_score(pages)\n",
    "- Toutes les fonctions acceptent une liste de titres d’articles et renvoient\n",
    "  un DataFrame indexé par \"page\" avec au moins la colonne \"value\".\n",
    "\n",
    "Étapes :\n",
    "1. Récupération des métriques unitaires.\n",
    "2. Mise à l’échelle 0‑1 par min‑max.\n",
    "3. Agrégation pondérée en trois pôles : Heat, Quality, ActorRisk.\n",
    "4. Score global = α*Heat + β*ActorRisk – γ*Quality.\n",
    "\n",
    "Vous pouvez ajuster les poids HEAT_WEIGHTS, QUALITY_WEIGHTS, RISK_WEIGHTS\n",
    "et GLOBAL_WEIGHTS selon la validation empirique.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ────────────────────────────────────────────  Poids (modifiable) ─────────────\n",
    "HEAT_WEIGHTS    = {\n",
    "    \"revert_rate\": 0.30,\n",
    "    \"protection_level\": 0.20,\n",
    "    \"pageview_spike\": 0.30,\n",
    "    \"talk_intensity\": 0.20,\n",
    "}\n",
    "QUALITY_WEIGHTS = {\n",
    "    \"citation_gap\": -0.30,      # négatif : plus de gap = moins de qualité\n",
    "    \"article_quality\": 0.40,\n",
    "    \"source_age\": -0.10,        # ancienneté élevée -> pénalité\n",
    "    \"readability\": 0.20,\n",
    "    \"unreliable_refs\": -0.20,\n",
    "}\n",
    "RISK_WEIGHTS    = {\n",
    "    \"anon_share\": 0.25,\n",
    "    \"sockpuppet_score\": 0.25,\n",
    "    \"micro_edits\": 0.20,\n",
    "    \"author_revertrisk\": 0.20,\n",
    "    \"automod_flag\": 0.10,\n",
    "}\n",
    "GLOBAL_WEIGHTS  = {\"heat\": 0.4, \"quality\": -0.3, \"risk\": 0.3}\n",
    "\n",
    "# ────────────────────────────────────────────  Helpers ────────────────────────\n",
    "\n",
    "def min_max_scale(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Ramène une série sur [0,1].\"\"\"\n",
    "    if series.empty:\n",
    "        return series\n",
    "    return (series - series.min()) / (series.max() - series.min() or 1)\n",
    "\n",
    "@dataclass\n",
    "class MetricResult:\n",
    "    name: str\n",
    "    values: pd.Series  # index = page, value = métrique brute\n",
    "\n",
    "@dataclass\n",
    "class ScoringResult:\n",
    "    heat: pd.Series\n",
    "    quality: pd.Series\n",
    "    risk: pd.Series\n",
    "    global_score: pd.Series\n",
    "\n",
    "# ────────────────────────────────────────────  Pipeline ───────────────────────\n",
    "\n",
    "def compute_scores(pages: List[str], start: str, end: str) -> ScoringResult:\n",
    "    \"\"\"Calcule les quatre scores pour la liste de pages entre start et end.\"\"\"\n",
    "\n",
    "    # 1. Collecte des métriques unitaires\n",
    "    from ano_editor   import get_anon_edit_share        # % anon edits\n",
    "    from edit         import get_revert_rate            # revert_rate\n",
    "    from pageviews    import get_pageview_spikes        # pageview_spike\n",
    "    from protection   import get_protection_level       # protection_level\n",
    "    from taille_talk  import get_talk_activity          # talk_intensity\n",
    "    from ref          import get_citation_gap           # citation_gap\n",
    "    from readability  import get_readability_score      # readability\n",
    "    #from val          import get_unreliable_ref_share   # part refs peu fiables\n",
    "    #from val          import get_source_age_avg         # age moyen des sources\n",
    "    #from sockdetect   import get_sockpuppet_score       # sockpuppet_score\n",
    "    #from val          import get_micro_edit_rate        # micro_edits\n",
    "    from edit         import get_author_revertrisk      # author_revertrisk\n",
    "    #from automod      import get_automod_flag_count     # automod_flag\n",
    "    #from artqual      import get_article_quality        # article_quality\n",
    "\n",
    "    data: Dict[str, pd.Series] = {}\n",
    "\n",
    "    data[\"revert_rate\"]      = get_revert_rate(pages, start, end)\n",
    "    data[\"protection_level\"] = get_protection_level(pages)\n",
    "    data[\"pageview_spike\"]   = get_pageview_spikes(pages, start, end)\n",
    "    data[\"talk_intensity\"]   = get_talk_activity(pages, start, end)\n",
    "\n",
    "    data[\"citation_gap\"]     = get_citation_gap(pages)\n",
    "    data[\"article_quality\"]  = get_article_quality(pages)\n",
    "    data[\"source_age\"]       = get_source_age_avg(pages)\n",
    "    data[\"readability\"]      = get_readability_score(pages)\n",
    "    data[\"unreliable_refs\"]  = get_unreliable_ref_share(pages)\n",
    "\n",
    "    data[\"anon_share\"]       = get_anon_edit_share(pages, start, end)\n",
    "    data[\"sockpuppet_score\"] = get_sockpuppet_score(pages)\n",
    "    data[\"micro_edits\"]      = get_micro_edit_rate(pages, start, end)\n",
    "    data[\"author_revertrisk\"] = get_author_revertrisk(pages, start, end)\n",
    "    data[\"automod_flag\"]     = get_automod_flag_count(pages)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    # 2. Normalisation 0‑1\n",
    "    df_norm = df.apply(min_max_scale, axis=0)\n",
    "\n",
    "    # 3. Agrégation par pôle\n",
    "    heat    = (df_norm[list(HEAT_WEIGHTS.keys())]    * pd.Series(HEAT_WEIGHTS)).sum(axis=1)\n",
    "    quality = (df_norm[list(QUALITY_WEIGHTS.keys())] * pd.Series(QUALITY_WEIGHTS)).sum(axis=1)\n",
    "    risk    = (df_norm[list(RISK_WEIGHTS.keys())]    * pd.Series(RISK_WEIGHTS)).sum(axis=1)\n",
    "\n",
    "    # 4. Score global\n",
    "    global_score = (pd.concat([\n",
    "        heat.rename(\"heat\"),\n",
    "        quality.rename(\"quality\"),\n",
    "        risk.rename(\"risk\")], axis=1) * pd.Series(GLOBAL_WEIGHTS)).sum(axis=1)\n",
    "\n",
    "    return ScoringResult(heat, quality, risk, global_score)\n",
    "\n",
    "# ────────────────────────────────────────────  Exécution directe ─────────────\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse, json\n",
    "    parser = argparse.ArgumentParser(description=\"Calcule les scores Wikipédia PROMPT.\")\n",
    "    parser.add_argument(\"pages\", nargs=\"+\", help=\"Titres d’articles Wikipédia avec _\")\n",
    "    parser.add_argument(\"--start\", default=\"2023-01-01\", help=\"Date début YYYY-MM-DD\")\n",
    "    parser.add_argument(\"--end\",   default=\"2023-12-31\", help=\"Date fin YYYY-MM-DD\")\n",
    "    parser.add_argument(\"--json\",  action=\"store_true\", help=\"Sortie JSON plutôt que tableau\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    res = compute_scores(args.pages, args.start, args.end)\n",
    "    output = pd.DataFrame({\n",
    "        \"heat\": res.heat,\n",
    "        \"quality\": res.quality,\n",
    "        \"risk\": res.risk,\n",
    "        \"global\": res.global_score\n",
    "    })\n",
    "\n",
    "    if args.json:\n",
    "        print(output.to_json(orient=\"index\", indent=2, force_ascii=False))\n",
    "    else:\n",
    "        print(output.round(3).to_markdown())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
